{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece12ae0-adfc-4f73-b9cf-ef4a0ebb7903",
   "metadata": {},
   "source": [
    "# Intro \n",
    "\n",
    "Previous Bayesian Theory of Mind models gave insights into mentalizing at the computational level, but not neccesarily the representations or algorithms underlying mental state inference. Previous models generally do not scale to large hypothesis spaces either.\n",
    "\n",
    "What sorts of representations do people have of others' mental states? How do people simplify complex inference problems?\n",
    "\n",
    "Recent work from Tamir & Thornton (2018; 2021) has mapped out certain abstract dimensions that organize people's neural representations of others' mental states (specifically emotions and other broad mental states, like \"drunkeness\" for instance). These dimensions of Valence, Rationality, and Social Impact comprise the 3D Mind Model. They have also mapped out abstract dimensions for observing others' actions (i.e. the ACT-FASTaxonomy).\n",
    "\n",
    "Below I examine two Bayesian models which predict mental states given some action, or P(mental state|action). A higher dimensional model considers a vast list of mental states and actions, and the discrete probabilities which relate them. Alternatively, using Tamir & Thornton's abstract dimensions can offer a potentially more efficient way of searching this hypothesis space, by performaing inference over a low dimensional vector space, made up of the abstract dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a56e8-bdc1-474f-b4f2-09b04481021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as sp\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ea8f7-3725-41af-a363-535f6c1522c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPosteriors = pd.read_csv('posteriorRatings.csv')\n",
    "dfLikelihoods = pd.read_csv('likelihoodRatings.csv')\n",
    "dfPriors = pd.read_csv('priorRatings.csv')\n",
    "actionCoordinates = pd.read_csv('pilotActions.csv')\n",
    "stateCoordinates = pd.read_csv('pilotStates.csv')\n",
    "\n",
    "stateCoordinates=stateCoordinates[['Valence', 'Social_Impact', 'Rationality-reverse-coded']].rename(index=stateCoordinates['States'])\n",
    "actionCoordinates=actionCoordinates[['Abstraction', 'Animacy', 'Spiritualism', 'Food', 'Creation', 'Tradition']].rename(index=actionCoordinates['Action'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853ba3d-eadd-43ad-b270-59fb5ddff3e3",
   "metadata": {},
   "source": [
    "# **High-Dimensional / Discrete Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54036a-ea84-422f-a017-01b38550d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def priorTable(df, stim):\n",
    "    priorDict = {}\n",
    "    for state in list(stim):\n",
    "        priorDict[state] = (sum([df['rating'][i] for i in range(len(df)) if df['stim1'][i] == state])/10)\n",
    "    return priorDict\n",
    "\n",
    "def likelihoodTable(df, states, actions):\n",
    "    dfPost = pd.DataFrame(columns = states, index= actions)\n",
    "    for act in actions:\n",
    "        for state in states:\n",
    "            num = 0\n",
    "            for row in range(len(df)):\n",
    "                if df['stim2'][row] == act and df['stim1'][row] == state:\n",
    "                    if math.isnan(dfPost[state][act]):\n",
    "                        dfPost[state][act] = df['rating'][row]\n",
    "                        num = num + 1\n",
    "                    elif num == 9:\n",
    "                        dfPost[state][act] = (df['rating'][row]+dfPost[state][act])/10\n",
    "                    else:\n",
    "                        dfPost[state][act] = df['rating'][row]+dfPost[state][act]\n",
    "                        num = num + 1\n",
    "    return dfPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e37b0-663d-409e-bbd1-0a5c302e1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_dim_Likelihood = likelihoodTable(dfLikelihoods, stateCoordinates.index, actionCoordinates.index)\n",
    "hi_dim_Prior = priorTable(dfPriors, stateCoordinates.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a358a22-8f6d-4d85-8592-b4e314e4c6a0",
   "metadata": {},
   "source": [
    "# **Low-Dimensional / Vector-Space Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499b252-8da5-4da5-aae8-6c5162345793",
   "metadata": {},
   "source": [
    "## Prior\n",
    "\n",
    "The prior is a Multivariate Normal distribution over the 3 mental state dimensions, fit from the Prior rating data. I use weighted datapoints to fit the distribution, the weights being people's probability ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbbc1e-a352-4189-8552-889f0f678900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MVprior(dfPr, sCoord):\n",
    "    #get datapoints (abstract mental state values) and weights \n",
    "    weights = np.array(dfPr['rating'])\n",
    "    datapoints = np.array([sCoord.loc[state] for state in dfPr['stim1']])\n",
    "    \n",
    "    means = np.average(datapoints, axis=0, weights=weights) #mean vector     \n",
    "    cov = np.cov(datapoints.T, aweights=weights) #covariance matrix\n",
    "    return means, cov\n",
    "\n",
    "prior_means, prior_cov = MVprior(dfPriors, stateCoordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a166dc5-1c21-4f04-af55-8d9a84f3c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "priorMVN = sp.multivariate_normal(prior_means, prior_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccda58-fbb5-4abc-b6ae-a1313bd25953",
   "metadata": {},
   "source": [
    "## Likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5905504-8202-4b72-8ab5-771f604546a6",
   "metadata": {},
   "source": [
    "The likelihood requires some mapping from points in action space and points in mental state space. This mapping is unknown, so I show both a linear (separate multiple regression equations) approach and a non-linear (neural network) approach, which end up not being very different.\n",
    "\n",
    "Specifically, I use PyMC to do Bayesian regression and a Bayesian neural network so the output for new predictions is a probability distribution (representing people's likelihood distribution).\n",
    "\n",
    "To find these statistical mappings I use the data from the likelihood ratings. X and Y are the abstract values for actions and mental states respectively. These are used to fit the parameters for both the regression and neural network, but importantly, I use the probabiliy ratings people as \"weights\" on the datapoints. Instead of scaling the error like some do for weighted data in frequentist stats, I scale the log probability (logp) of that data under the model. Thus, higher probability ratings shift the model's parameters more during training. \n",
    "\n",
    "### Get x and y datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2901f19-5fac-4c4b-a3d9-fdac7820fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLikelihoodx_y(sCoord, aCoord, dfLik):\n",
    "\n",
    "    x=[]\n",
    "    y=[]\n",
    "    \n",
    "    for r in range(len(dfLik)):\n",
    "        state = dfLik['stim1'][r]\n",
    "        act = dfLik['stim2'][r]\n",
    "        x.append([aCoord['Abstraction'][act], aCoord['Animacy'][act],\n",
    "                  aCoord['Spiritualism'][act], aCoord['Food'][act], \n",
    "                  aCoord['Creation'][act], aCoord['Tradition'][act]])\n",
    "        y.append([sCoord['Valence'][state], sCoord['Social_Impact'][state], \n",
    "                   sCoord['Rationality-reverse-coded'][state]])\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    weights = dfLik['rating']+1\n",
    "    return np.array(x), np.array(y), np.array(weights)\n",
    "\n",
    "x, y, w = getLikelihoodx_y(stateCoordinates, actionCoordinates, dfLikelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe42a1-1148-4219-9150-777fafa03dfe",
   "metadata": {},
   "source": [
    "Now the same, but for the posteriors we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac937199-5975-4065-8b8c-fb337566cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosteriorx_y(sCoord, aCoord, dfPost):\n",
    "    \n",
    "    x=[]\n",
    "    y=[]\n",
    "    \n",
    "    for r in range(len(dfPost)):\n",
    "        act = dfPost['stim1'][r]\n",
    "        state = dfPost['stim2'][r]\n",
    "        x.append([aCoord['Abstraction'][act], aCoord['Animacy'][act],\n",
    "                  aCoord['Spiritualism'][act], aCoord['Food'][act], \n",
    "                  aCoord['Creation'][act], aCoord['Tradition'][act]])\n",
    "        y.append([sCoord['Valence'][state], sCoord['Social_Impact'][state], \n",
    "                   sCoord['Rationality-reverse-coded'][state]])\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    ratings = dfPost['rating']\n",
    "    return np.array(x), np.array(y), np.array(ratings)\n",
    "\n",
    "xP, yP, posteriorRatings = getPosteriorx_y(stateCoordinates, actionCoordinates, dfPosteriors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a99bbf-78cf-40fa-90a8-175c5d8b2e91",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "Fit the parameters of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232227c8-41a7-4898-a90d-c953d7ade0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as linearModel:\n",
    "    \n",
    "    #model's data\n",
    "    weights = pm.Data(\"weights\", np.array([w, w, w]).T, mutable=False)\n",
    "    x_obs = pm.MutableData('x_observation', x)\n",
    "    y_obs = pm.MutableData('y_observation', y)  \n",
    "    \n",
    "    # define priors over parameters\n",
    "    betas = pm.Normal('slopes_matrix', 0., 10., shape=(6, 3))\n",
    "    beta0 = pm.Normal('intercepts', 0., 10., shape=(1,3))\n",
    "\n",
    "    # predictions\n",
    "    y_pred = pm.Deterministic('y_prediction', pm.math.dot(x_obs, betas) + beta0)\n",
    "    \n",
    "    sigmas = pm.HalfNormal('sigmas', 25., shape=3)\n",
    "    \n",
    "    obs = pm.Normal('observation', y_pred, sigmas, observed=y_obs)\n",
    "    \n",
    "    #Weighted datapoints \n",
    "    #note: pm.Potential doesn't affect later sampling predictions from model, only for infering parameters\n",
    "    obs_weighted = pm.Potential('observation_weighted', \n",
    "                                weights*pm.logp(pm.Normal.dist(y_pred, sigmas), y_obs))\n",
    "\n",
    "    \n",
    "    #use MCMC to sample\n",
    "    trace = pm.sample(draws=12000, tune=12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66f357-09cf-459d-8c10-84b8249190e7",
   "metadata": {},
   "source": [
    "Now to make predictions for the likelihood distributions on the Posterior experiment trials we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec527a0-0134-42a6-b691-a8132fbcd041",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions =[actionCoordinates.loc[act] for act in actionCoordinates.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f65197-fc0a-4ff2-99c7-16e5183aa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "with linearModel:\n",
    "    pm.set_data({'x_observation': xP})\n",
    "    predictive = pm.sample_posterior_predictive(trace)\n",
    "    linearModel_predictions = np.mean(predictive['posterior_predictive']['observation'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9a6a2-f2b7-4a86-a58f-123d261efb37",
   "metadata": {},
   "source": [
    "### Non-linear Model\n",
    "Same steps as for the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350d5b1-ea28-4ce9-9b9f-ab76224ecdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=6\n",
    "\n",
    "with pm.Model() as nn_model:\n",
    "\n",
    "    #Weight Datapoints\n",
    "    weights = pm.Data(\"weights\", np.array([w, w, w]).T, mutable=False) \n",
    "\n",
    "    #X and Y\n",
    "    x_obs = pm.MutableData('x_obs', x)\n",
    "    y_obs = pm.MutableData('y_obs', y)\n",
    "\n",
    "    # Input -> Layer 1\n",
    "    weights_1 = pm.Normal('w_1', mu=0, sigma=20,\n",
    "                          shape=(6, n_hidden))\n",
    "    b_01 = pm.Normal('intercept_1', 0., 25., shape=(1,n_hidden))\n",
    "    acts_1 = pm.Deterministic('activations_1',\n",
    "                              pm.math.tanh(pm.math.dot(x_obs, weights_1))+b_01)\n",
    "\n",
    "    # Layer 1 -> Layer 2\n",
    "    weights_2 = pm.Normal('w_2', mu=0, sigma=20,\n",
    "                          shape=(n_hidden, n_hidden))\n",
    "    b_02 = pm.Normal('intercept_2', 0., 25., shape=(1,n_hidden))\n",
    "    acts_2 = pm.Deterministic('activations_2',\n",
    "                              pm.math.tanh(pm.math.dot(acts_1, weights_2))+b_02)\n",
    "    \n",
    "    # Layer 2 -> Layer 3\n",
    "    weights_3 = pm.Normal('w_3', mu=0, sigma=20,\n",
    "                            shape=(n_hidden, 3))\n",
    "    b_03 = pm.Normal('intercept_3', 0., 25., shape=(1,3))\n",
    "    acts_3 = pm.Deterministic('activations_3',\n",
    "                              pm.math.tanh(pm.math.dot(acts_2, weights_3)+b_03) \n",
    "\n",
    "    # Layer 3 -> Output Layer\n",
    "    weights_out = pm.Normal('w_out', mu=0, sigma=20,\n",
    "                            shape=(n_hidden, 3))\n",
    "    b_04 = pm.Normal('intercept_4', 0., 25., shape=(1,3))\n",
    "    acts_out = pm.Deterministic('activations_out',\n",
    "                                pm.math.dot(acts_3, weights_out)+b_04) \n",
    "\n",
    "    # Define likelihood\n",
    "    sigmas = pm.HalfNormal('sigmas', 50., shape=3)\n",
    "    out = pm.Normal('out', acts_out, sigmas, observed=y_obs)\n",
    "                              \n",
    "    #Weighted datapoints\n",
    "    out_weighted = pm.Potential('out_w', weights*pm.logp(pm.Normal.dist(acts_out, sd_dist), y_obs))\n",
    "\n",
    "    #use MCMC to sample\n",
    "    trace_nn = pm.sample(draws=5000, tune=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5241a-a320-42fb-8c5f-bcab9e055595",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nn_model:\n",
    "    pm.set_data({'x_obs': xP})\n",
    "    predictive_nn = pm.sample_posterior_predictive(trace_nn)\n",
    "    nn_model_predictions = predictive_nn['posterior_predictive']['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1e459-6ccf-4b55-8dcd-84a9fe4300e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel_predictions = np.mean(linearModel_predictions, axis=0)\n",
    "nn_model_predictions = np.mean(nn_model_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df7208-8c20-431e-8ded-1c3f63ecf30c",
   "metadata": {},
   "source": [
    "### Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b402823-4b84-4395-bf60-8674b7b3cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHybridx_y(sCoord, aCoord, dfLike):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    actDict={}\n",
    "    for a in aCoord['Action']:\n",
    "        actDict[a] = []\n",
    "    for r in range(len(dfLike)):\n",
    "        sta = dfLike['stim1'][r]\n",
    "        act = dfLike['stim2'][r]\n",
    "        y1 = sCoord['Valence'][sta]\n",
    "        y2 = sCoord['Social_Impact'][sta]\n",
    "        y3 = sCoord['Rationality-reverse-coded'][sta]\n",
    "        w = dfLike['rating'][r]\n",
    "        actDict[act].append([y1,y2,y3,w])    \n",
    "    \n",
    "    return actDict\n",
    "\n",
    "def getMVNsactDict(actDict):\n",
    "    for act in actDict:\n",
    "        Ws = [w[3] for w in actDict[act]]\n",
    "        datapoints = np.array(actDict[act])[:,:3]\n",
    "        av = np.average(datapoints, axis=0, weights=Ws)     \n",
    "        cov = np.cov(datapoints.T, aweights=Ws)\n",
    "        likelihoodMVN = sp.multivariate_normal(av, cov)\n",
    "        actDict[act] = likelihoodMVN\n",
    "\n",
    "    return actDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df3c31-da8e-4058-a452-c5364f1ac048",
   "metadata": {},
   "outputs": [],
   "source": [
    "actDict = getHybridx_y(sCoord, aCoord, dfL)\n",
    "hybridLikelihooodDict = getMVNsactDict(actDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d9d9f-6a28-4de2-9fc5-996db78d61d1",
   "metadata": {},
   "source": [
    "# **Compute Posterior Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e0659c-7a52-44fe-9411-8e977590760d",
   "metadata": {},
   "source": [
    "Combines the priors and likelihoods for each variation of the vector space model, and returns predictions for each posterior trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b75b2-5085-4522-860b-aecfe4e56379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_LikPri_discretely(MS, stateDims, L, P, justL=False):\n",
    "    listProbs = []\n",
    "    for m in range(len(stateDims)):\n",
    "        stateVector = [stateDims['Valence'][m],\n",
    "           stateDims['Rationality-reverse-coded'][m],\n",
    "           stateDims['Social_Impact'][m]]\n",
    "        if (P == None) & (justL):\n",
    "            prob = L.pdf(stateVector)\n",
    "        else:\n",
    "            prob = L.pdf(stateVector)*P.pdf(stateVector)\n",
    "        listProbs.append(prob)\n",
    "        if stateDims['States'][m] == MS:\n",
    "            index = m                    \n",
    "    normalizedProbs = [p/sum(listProbs) for p in listProbs]\n",
    "    return normalizedProbs[index]\n",
    "\n",
    "def modelCorrelation(human_ratings, model_probs):\n",
    "    return sp.pearsonr(human_ratings, model_probs)\n",
    "\n",
    "def runModel(posterior_df, stateDims, Lpredictions, priorMVN=None, modelType='nn', justLik=False):\n",
    "    finalPreds = []\n",
    "    if modelType == 'nn':    \n",
    "        for k in range(len(posterior_df)):\n",
    "            av = np.mean(Lpredictions[:,k,:], axis=0)     # (5000, 5760, 3)\n",
    "            cov = np.cov(Lpredictions[:,k,:].T)\n",
    "            likelihoodMVN = sp.multivariate_normal(av, cov)\n",
    "            normedProb = combine_LikPri_discretely(posterior_df['stim2'][k], stateDims, likelihoodMVN, priorMVN, justL=justLik)\n",
    "            finalPreds.append(normedProb)\n",
    "    elif modelType == 'hybrid':\n",
    "        for k in range(len(posterior_df)):\n",
    "            likelihoodMVN = Lpredictions[posterior_df['stim1'][k]] #predictions is dictionary of MVNs\n",
    "            normedProb = combine_LikPri_discretely(posterior_df['stim2'][k], stateDims, likelihoodMVN, priorMVN, justL=justLik)\n",
    "            finalPreds.append(normedProb)\n",
    "\n",
    "    results = modelCorrelation(posterior_df['rating'], finalPreds)\n",
    "    print(results)\n",
    "        \n",
    "    return results, finalPreds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bc679-f440-454a-8eaa-34b3b8f23f9d",
   "metadata": {},
   "source": [
    "Now the same, but for the Discrete Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9dc578-a368-4d21-9705-4f719d3f1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runDiscreteModel(df, lik, pri):\n",
    "    predictions = []\n",
    "    for row in range(len(df)):\n",
    "        act = df['stim1'][row]\n",
    "        sta = df['stim2'][row]\n",
    "        pred = (lik[sta][act] * pri[sta])\n",
    "        prediction = pred/(sum(\n",
    "            [(lik[state][act] * pri[state]) for state in lik.columns]\n",
    "        ))\n",
    "        predictions.append(prediction)\n",
    "    return sp.pearsonr(predictions, df['rating']), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d076b-5bc4-418e-bc83-9c7c0e30fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aCoord = pd.read_csv('pilotActions.csv')\n",
    "sCoord = pd.read_csv('pilotStates.csv')\n",
    "\n",
    "sCoord=sCoord.rename(index=sCoord['States'])\n",
    "aCoord=aCoord.rename(index=aCoord['Action'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154aaf9-a440-46a0-b191-aeb0e5269815",
   "metadata": {},
   "source": [
    "These functions below return 2 variables: an overall correlation coefficient and a list of predictions from that model for each trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cdc2be-b1f1-4aef-b621-4a63a1210271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear\n",
    "result_lm, pred_lm = runModel(dfPosteriors, sCoord, linearModel_predictions, \n",
    "                                   priorMVN = priorMVN, \n",
    "                                   modelType='nn', justLik=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7a715-a77b-413a-83fa-c29f80f1ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-linear\n",
    "result_nn, pred_nn = runModel(dfPosteriors, sCoord, nn_model_predictions, \n",
    "                                   priorMVN = priorMVN, \n",
    "                                   modelType='nn', justLik=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbed71b-9259-47b9-9ff4-6f075e85241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid\n",
    "result_hm, pred_hm = runModel(dfPosteriors, sCoord, hybridLikelihooodDict,\n",
    "                                   priorMVN = priorMVN,\n",
    "                                   modelType='hybrid', justLik=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f4d28-bfd2-47a8-81e2-aa9e28263053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrete\n",
    "result_discrete, pred_discrete = runDiscreteModel(dfPosteriors, \n",
    "                                                  hi_dim_Likelihood, hi_dim_Prior) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
